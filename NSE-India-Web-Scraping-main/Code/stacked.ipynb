{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"D:\\\\programs\\\\ads_flask\\\\logres_op\\\\data\\\\\"\n",
    "model_dir=\"D:\\\\programs\\\\ads_flask\\\\logres_op\\\\model\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld=[]\n",
    "files=[]\n",
    "for root, dirs, files in os.walk(data_dir, topdown=False):\n",
    "   for name in files:\n",
    "      ld.append(os.path.join(root, name))\n",
    "for i in range(len(files)):\n",
    "   files[i]=files[i].replace(\".csv\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=[]\n",
    "files=[]\n",
    "for root, dirs, files in os.walk(model_dir, topdown=False):\n",
    "   for name in files:\n",
    "      lm.append(os.path.join(root, name))\n",
    "for i in range(len(files)):\n",
    "   files[i]=files[i].replace(\".h5\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "def conv_logret_close(y,val):\n",
    "    yc=[]\n",
    "    for i in range(len(y)):\n",
    "        if i==0:\n",
    "            yc.append((math.e**y)*val)\n",
    "        else:\n",
    "            yc.append((math.e**y)*yc[i-1]) \n",
    "    return np.array(yc).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002305C67CEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023061220EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "    df=pd.read_csv(ld[i])\n",
    "    m=tf.keras.models.load_model(lm[i])\n",
    "    x=np.array(df[\"logret\"][df[\"logret\"].size-91:df[\"logret\"].size-1])\n",
    "    x=x.reshape(1,x.shape[0],1)\n",
    "    y=m.predict(x)\n",
    "    y=conv_logret_close(y,df[\"close \"][df[\"OPEN \"].size-1])\n",
    "    data_list.append([files[i],df[\"logret\"].sum()/df[\"logret\"].size,y[89]-float(df[\"close \"].tail(1)),(y[89]-float(df[\"close \"].tail(1)))/float(df[\"close \"].tail(1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         stock  10Y_mean_logret  expected gain  pct change\n",
       " 0     ADANIENT         0.001746      32.103320    0.013294\n",
       " 46       TITAN         0.001042      -2.479004   -0.000834\n",
       " 10   BRITANNIA         0.000823       1.612988    0.000319\n",
       " 41  TATACONSUM         0.000740       0.462732    0.000539\n",
       " 31      MARUTI         0.000727      10.459570    0.001102\n",
       " 2   APOLLOHOSP         0.000671       0.941211    0.000182\n",
       " 7   BAJFINANCE         0.000657      20.669727    0.002851\n",
       " 48         UPL         0.000649       1.944409    0.002845\n",
       " 1   ADANIPORTS         0.000637      -0.019055   -0.000026\n",
       " 33   NESTLEIND         0.000611      48.108203    0.002096,\n",
       "          stock  10Y_mean_logret  expected gain  pct change\n",
       " 0     ADANIENT         0.001746      32.103320    0.013294\n",
       " 7   BAJFINANCE         0.000657      20.669727    0.002851\n",
       " 48         UPL         0.000649       1.944409    0.002845\n",
       " 14     DRREDDY         0.000337      12.772168    0.002606\n",
       " 25  INDUSINDBK         0.000413       3.343774    0.002575\n",
       " 3   ASIANPAINT        -0.000131       8.023877    0.002418\n",
       " 33   NESTLEIND         0.000611      48.108203    0.002096\n",
       " 34        NTPC         0.000109       0.370453    0.001976\n",
       " 19    HDFCBANK         0.000378       3.114380    0.001937\n",
       " 47  ULTRACEMCO         0.000609      14.707227    0.001784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=pd.DataFrame(data_list,columns=[\"stock\",'10Y_mean_logret',\"expected gain\",\"pct change\"])\n",
    "d.nlargest(10,'10Y_mean_logret'),d.nlargest(10,\"pct change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=d[[\"stock\",\"10Y_mean_logret\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(\"10Ymeanlogrte.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
